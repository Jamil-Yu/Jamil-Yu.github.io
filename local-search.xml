<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>[Information Theory] 复习时的一些心得理解</title>
    <link href="/2023/04/25/%5BInformation%20Theory%5D%20%E5%A4%8D%E4%B9%A0%E6%97%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%83%E5%BE%97/"/>
    <url>/2023/04/25/%5BInformation%20Theory%5D%20%E5%A4%8D%E4%B9%A0%E6%97%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%83%E5%BE%97/</url>
    
    <content type="html"><![CDATA[<h1 id="information-theory-复习时的一些心得">[Information Theory]复习时的一些心得</h1><h2 id="chapter-2">Chapter 2</h2><h3 id="一些定义">一些定义</h3><h4 id="信息熵联合熵条件熵">信息熵、联合熵、条件熵</h4><p>对信息熵的定义的理解：</p><ul><li><p>为什么要用log？</p><ul><li><p>对于某个概率为p的东西，我们想找一个东西描述它的信息，要满足以下条件：</p></li><li><blockquote><p>非负</p><p>如果概率是1，信息量为0</p><p>函数连续(这样比较好)</p><p>如果两件事独立，一起发生的信息是单独发生的信息之和</p></blockquote><p>这样就可以得出<span class="math inline">\(I(p) \proptolog\frac{1}{p}\)</span></p></li></ul></li><li><p>知道这个之后，<spanclass="math inline">\(H\)</span>的定义是怎么出来的？</p><ul><li>刚才讨论的是对于<span class="math inline">\(p\)</span>的，对于<spanclass="math inline">\(H\)</span>，就是看一个随机变量，它具有一定的概率分布，我们要求它的信息。那么显然就可以理解为它对于刚在给定概率下信息的期望(相当于求个和或者说积个分，把每个<spanclass="math inline">\(p\)</span>下贡献的信息累加起来)</li><li>因此我们有了</li></ul><p><span class="math display">\[H(X) = \mathbb{E}_plog\frac{1}{p(x)}\]</span></p><hr /></li></ul><p>理解了上面所说，联合熵、条件熵也就不难理解了，不过是看联合概率、条件概率罢了</p><hr /><h4 id="信息熵的链式法则">信息熵的链式法则</h4><p>对于Chain rule的理解：</p><ul><li>理解一下<span class="math inline">\(H(X,Y) = H(X) +H(X|Y)\)</span>即可</li><li>想看看X，Y的信息，我们先知道了X的信息，此时由于X、Y之间可能存在一定的相关性，我们对Y已经有了一点点的了解，剩下的关于X，Y的信息即为H(X|Y)</li><li>跟同学交流时，他说有点像是线性代数中的Cramer法则？就好像分解成一些正交空间一样。有点感觉。</li></ul><p>根据上面的第二条，似乎互信息用<span class="math inline">\(I(X,Y) =H(X) - H(X|Y)\)</span>来表示是很显然的一件事了</p><hr /><h4 id="kl散度相对熵">KL散度（相对熵）</h4><p>首先我们看看公式 <span class="math display">\[D(p||q) = \sum_{x\in\mathcal{X}}p(x)log\frac{p(x)}{q(x)}  =\mathbb{E}_plog\frac{p(X)}{q(X)}\]</span> 为了延续上面的理解方式，可以写成 <span class="math display">\[D(p||q) = \mathbb{E}_p(log\frac{1}{q(X)}-log\frac{1}{p(X)})\]</span>E中的第一项似乎是在一个给定值下q的信息，第二项是p的信息，好像就是信息差。而这件事是对p的期望，似乎是从p的角度看待这件事的一般，从p的角度看两者的差距。</p><p>在网上找到了一种我觉得很妙的解释：</p><blockquote><p>假设P(X=0)=0.8，P(X=1)=0.2，那么我们可以用0来编码消息0，用10来编码消息1，这样平均每个消息的编码长度为：L(P) = 0.8 * 1 + 0.2 * 2 = 1.2 bits 这也等于X的熵H(P)。但是如果我们不知道X的真实概率分布P(X)，而只知道一个近似的概率分布Q(X)，那么我们可能会用不同的编码方案来传输消息。例如，假设Q(X=0)=0.5，Q(X=1)=0.5，那么我们可能会用01来编码消息0，用11来编码消息1，这样平均每个消息的编码长度为：L(Q) = 0.8 * 2 + 0.2 * 2 = 2 bits 这也等于X的交叉熵H(P,Q)。可以看出，由于我们使用了一个不准确的概率分布Q(X)来编码消息，导致了平均每个消息的编码长度增加了0.8bits，这就是用Q(X)来近似P(X)所造成的信息损失。这个信息损失就是KL散度D(P||Q)：D(P||Q) = L(Q) - L(P) = H(P,Q) - H(P) = 0.8 bits<strong>也就是说，KL散度衡量了如果我们使用Q(X)来代替P(X)，那么每个消息需要额外传输多少比特数。</strong></p></blockquote><blockquote><p>回头再验证一下</p></blockquote><p>后来我们知道，KL散度是肯定大于0的，但是显然每个点两者信息的大小关系有可能有大有小，而最后大于0，反映了一种最优性和必然性，回头再看看。</p><hr /><h4 id="互信息和dl-散度的关系">互信息和DL-散度的关系</h4><p><span class="math display">\[I(X,Y) = D[p(X,Y)||p(X)p(Y)]\]</span></p><p>这又很神奇，后面证明正的时候再看看</p><hr /><h4 id="条件互信息">条件互信息</h4><p><span class="math display">\[I(X;Y|Z) = H(X| Z) - H(X|Y, Z)\]</span></p><p>这可以从信息增益的角度理解，也可以写成<spanclass="math inline">\(\mathbb{E}\)</span>的形式从KL-D的角度理解</p><hr /><h4 id="互信息的链式法则">互信息的链式法则</h4><p><span class="math display">\[I(X_1,X_2\cdots X_n;Y) = \sum_{i=1}^{n}I(X_i;Y|X_{i-1},\cdots,X_1)\]</span></p><p>理解上，跟信息熵的链式法则一样，只不过之前的信息现在变成了和Y之间的互信息</p><hr /><h4 id="条件相对熵">条件相对熵</h4><p><span class="math display">\[D[p(y|x) || q(y|x)] = \mathbb{E}_{x,y}log\frac{p(Y|X)}{q(Y|X)}\]</span></p><hr /><h4 id="相对熵的链式法则">相对熵的链式法则</h4><p><span class="math display">\[D[p(x, y)||q(x,y)] = D[p(x)||q(x)] + D[p(y|x)||q(y|x)]\]</span></p><p>这个要怎么很直观地理解？</p><blockquote><p>相对熵可以看作是两个分布之间的差异或不相似度的度量，而链式法则可以看作是一种将这种差异分解为局部差异和条件差异的方法。</p></blockquote><h3 id="一些推论">一些推论</h3><p>首先，教材引入了Jensen不等式，这在几何上非常容易理解，不赘述</p><p>结论： <span class="math display">\[f(x): convex\;\Rightarrow\;\mathbb{E}f(X) \ge f(\mathbb{E}X)\]</span> 以此证明 <span class="math display">\[D[p||q]\ge 0\]</span></p><p>数学上很好证，讲讲理解 <span class="math display">\[H(X) = \sum_xp(x)log\frac{1}{p(x)}\]</span></p><p><span class="math display">\[D[p(x)||q(x)] = \sum_x p(x)[log\frac{1}{q(x)}-log\frac{1}{p(x)}]\]</span></p><p>我们盯着这两个式子，<spanclass="math inline">\(log\frac{1}{p(x)}\)</span>随着<spanclass="math inline">\(p(x)\)</span>的增大而减小，是否就是说，在概率大的时候我们要挑选一个小一点的东西对它进行表示，概率小的时候用大一点的东西对它进行表示，那么最后我们总共的消耗比较小（编码的角度）</p><p>而对于KL散度，我们已经知道了<spanclass="math inline">\(p(x)\)</span>，那么对于每个概率点，用<spanclass="math inline">\(log\frac{1}{p(x)}\)</span>来表示应该是最优的，但是如果我们偏偏要用<spanclass="math inline">\(log\frac{1}{q(x)}\)</span>来对每个概率点表示，比如我们在P中有很大概率的时候，用了Q中有很小概率的东西进行了表示，那就造成了很大的损失，导致KL散度增加。每个点的改变的程度就是[]中的式子相减。因为函数的性质，总体加起来肯定会变大，这更说明了原来的表示的最优性。</p><hr /><h4 id="相对熵的凸性">相对熵的凸性</h4><p><span class="math display">\[D(\lambda p_1+(1-\lambda)p_2||\lambda q_1+(1-\lambda)q_2)\le \lambdaD(p_1||q_1)+(1-\lambda)D(p_2||q_2)\]</span></p><p>怎么理解？？？</p><hr /><p>Q：单个映射是不是也可以看成一个MC？</p>]]></content>
    
    
    
    <tags>
      
      <tag>Notes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[Record] 配置PyQt5 (Linux系统) </title>
    <link href="/2023/04/16/%5BRecord%5D%E9%85%8D%E7%BD%AEPyQt5%20(Linux%20%E7%B3%BB%E7%BB%9F)/"/>
    <url>/2023/04/16/%5BRecord%5D%E9%85%8D%E7%BD%AEPyQt5%20(Linux%20%E7%B3%BB%E7%BB%9F)/</url>
    
    <content type="html"><![CDATA[<h1 id="record配置pyqt5-linux-系统">[Record]配置PyQt5 (Linux 系统)</h1><blockquote><p>在Windows环境忙活了一下午都找不到东西，于是尝试使用Linux，果然方便快捷</p></blockquote><ul><li>First, create a new environment in anaconda</li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">conda create <span class="hljs-literal">-n</span> pyqt python=<span class="hljs-number">3.8</span><br></code></pre></td></tr></table></figure><ul><li>Go into the environment</li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">conda activate pyqt<br></code></pre></td></tr></table></figure><ul><li>Install Qt Designer</li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell">sudo apt<span class="hljs-literal">-get</span> install qttools5<span class="hljs-literal">-dev-tools</span><br>sudo apt<span class="hljs-literal">-get</span> install qttools5<span class="hljs-literal">-dev</span><br></code></pre></td></tr></table></figure><ul><li>Open the Qt Designer</li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-built_in">cd</span> /usr/lib/x86_64<span class="hljs-literal">-linux-gnu</span>/qt5/bin/ <br>./designer<br></code></pre></td></tr></table></figure><ul><li>Edit the file and save it</li><li>Transform the ui into python</li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">pyuic5 path/to/helloworld.ui <span class="hljs-literal">-o</span> path/to/helloworld.py<br></code></pre></td></tr></table></figure><p>上面的命令生成的代码只是一些定义的函数，并没有调用，执行之后并不会有任何界面显示，需要在另外的python文件中进行import之后调用；如果想要在单独一个文件中执行并显示图形结果，可以使用</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">pyuic5 <span class="hljs-literal">-x</span> path/to/helloworld.ui <span class="hljs-literal">-o</span> path/to/helloworld.py<br></code></pre></td></tr></table></figure><blockquote><p>感谢来自csdn的文章<ahref="https://blog.csdn.net/ayiya_Oese/article/details/116299610">链接</a></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>record</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[Semantic Segmentation] Some Classic network for Semantic Segmentation</title>
    <link href="/2023/03/09/Semantic%20segmentation/"/>
    <url>/2023/03/09/Semantic%20segmentation/</url>
    
    <content type="html"><![CDATA[<h1 id="semantic-segmentation">Semantic Segmentation</h1><ul><li>FCN</li><li>U-Net</li><li>PSPNet</li><li>Deeplab v1-3(+)</li></ul><h2 id="fcn">FCN</h2><blockquote><p>Our key insight is to build <strong>“fullyconvolutional”networks</strong> that take input of <strong>arbitrarysize</strong> and produce correspondingly-sized output with efficientinference and learning.</p></blockquote><blockquote><p>We then define <strong>a skip architecture</strong> that<strong>combines semantic information from a deep, coarse layer</strong>with appearance information from a shallow, fine layer to produceaccurate and detailed segmentations.</p></blockquote><p>Structure:</p><figure><img src="/typora-user-images/image-20230313202318039.png"alt="Structure of FCN" /><figcaption aria-hidden="true">Structure of FCN</figcaption></figure><p>The FCN will choose a classify network as backbone (e.g. VGGNet,ResNet). It abandon FC and replace them with Conv.</p><h4 id="details">Details:</h4><h2 id="unet">UNet</h2><p><strong>Structure:</strong></p><figure><img src="/typora-user-images/image-20230325195356603.png"alt="Structure of UNet" /><figcaption aria-hidden="true">Structure of UNet</figcaption></figure><h2 id="pspnet">PSPNet</h2><p><strong>Structure:</strong></p><figure><img src="/typora-user-images/image-20230325195446997.png"alt="Structure of PSPNet" /><figcaption aria-hidden="true">Structure of PSPNet</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[DL] Basic-Net</title>
    <link href="/2023/02/19/%5BDL%5DBasic-Net/"/>
    <url>/2023/02/19/%5BDL%5DBasic-Net/</url>
    
    <content type="html"><![CDATA[<h1 id="nets">Nets</h1><h2 id="杂七杂八的介绍">杂七杂八的介绍</h2><ul><li>LeNet 1994</li></ul><blockquote><p>是早期（1994年）的神经网络之一，用于手写数字识别，由卷积层，池化层，全连接层组成，网络结构如下图所示</p><figure><img src="/typora-user-images/image-20230313201432146.png"alt="Structure of LeNet" /><figcaption aria-hidden="true">Structure of LeNet</figcaption></figure></blockquote><ul><li>AlexNet 2012</li></ul><blockquote><p>是首个实用性很强的卷积神经网络由卷积操，池化层，全连接层，<strong>softmax层</strong>以及<strong>ReLU、Dropout</strong>构成。首次提出在2012年的ILSVRC大规模视觉识别竞赛上。其网络结构如下图所示：</p><figure><img src="/typora-user-images/image-20230313201406795.png"alt="Structure of AlexNet" /><figcaption aria-hidden="true">Structure of AlexNet</figcaption></figure></blockquote><ul><li>VGGNet 2014</li></ul><blockquote><p>VGGNet出现在2014年ILSVRC上比赛上获得了分类项目的第二名和定位项目的第一名，VGGNet相对于AlexNet堆叠了更多基础模块导致网络深度达到近二十层，另外它将之前5x5，7x7的卷积核替换成3x3的小卷积核，用2x2池化代替3x3，去除了局部响应归一化</p><p>。在训练高级别的网络时，可以先训练低级别的网络，用前者获得的权重初始化高级别的网络，可以加速网络的收敛。网络参数如下表所示：</p><figure><img src="/typora-user-images/image-20230313201420238.png"alt="Structure of VGGNet" /><figcaption aria-hidden="true">Structure of VGGNet</figcaption></figure></blockquote><ul><li><p>LeNet 1994</p></li><li><p>AlexNet 2012</p></li><li><p>VGGNet 2014</p></li><li><p>GoogleNet 2014</p></li><li><p>ResNet 2016</p></li><li><p>DenseNet 2017</p></li><li><p>SqueezeNet 2017</p></li><li><p>MobileNet 2017</p></li><li><p>SEnet 2018</p></li></ul><h2 id="lenet">LeNet</h2><blockquote><p>是一系列网络，包括LeNet 1-5</p><p>Yann LeCun 等人在 1990 年</p></blockquote><p>7层神经网络，包括3个卷积层，2个池化层，2个全连接层。所有卷积核5x5，stride = 1. 池化为全局，激活函数为Sigmoid</p><p>用pytorch展现网络架构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Reshape</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)<br>    <br>net = torch.nn.Sequential(<br>    Reshape(), <br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>), nn.Sigmoid(),  <span class="hljs-comment"># padding表示在边缘加2，因为本来是32x32的</span><br>    nn.AvgPool2d(<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">5</span>), nn.Sigmoid(),<br>    nn.AvgPool2d(<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>), <br>    nn.Flatten(),<br>    nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>), dtype=torch.float32)<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X = layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__, <span class="hljs-string">&#x27;output shape: \t&#x27;</span>, X.shape)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输出</span><br>Reshape output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>])<br>Conv2d output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>])<br>Sigmoid output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>])<br>AvgPool2d output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">14</span>, <span class="hljs-number">14</span>])<br>Conv2d output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>])<br>Sigmoid output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>])<br>AvgPool2d output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>])<br>Flatten output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">400</span>])<br>Linear output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">120</span>])<br>Sigmoid output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">120</span>])<br>Linear output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">84</span>])<br>Sigmoid output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">84</span>])<br>Linear output shape:  torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_accuracy_gpu</span>(<span class="hljs-params">net, data_iter, device=<span class="hljs-literal">None</span></span>): <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用GPU计算模型在数据集上的精度&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, nn.Module):<br>        net.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 设置为评估模式</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> device:<br>            device = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(net.parameters())).device<br>    <span class="hljs-comment"># 正确预测的数量，总预测的数量</span><br>    metric = d2l.Accumulator(<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(X, <span class="hljs-built_in">list</span>):<br>                <span class="hljs-comment"># BERT微调所需的（之后将介绍）</span><br>                X = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>            <span class="hljs-keyword">else</span>:<br>                X = X.to(device)<br>            y = y.to(device)<br>            metric.add(d2l.accuracy(net(X), y), y.numel())<br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch6</span>(<span class="hljs-params">net, train_iter, test_iter, num_epochs, lr, device</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear <span class="hljs-keyword">or</span> <span class="hljs-built_in">type</span>(m) == nn.Conv2d:<br>            nn.init.xavier_uniform_(m.weight)<br>    net.apply(init_weights)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;training on &quot;</span>, device)<br>    net.to(device)<br>    optimizer = torch.optim.SGD(net.parameters(), lr=lr)<br>    loss = nn.CrossEntropyLoss()<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs],<br>                            legend=[<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>])<br>    timer, num_batches = d2l.Timer(), <span class="hljs-built_in">len</span>(train_iter)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        metric = d2l.Accumulator(<span class="hljs-number">3</span>)<br>        net.train()<br>        <span class="hljs-keyword">for</span> i, (X, y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_iter):<br>            timer.start()<br>            optimizer.zero_grad()<br>            X, y = X.to(device), y.to(device)<br>            y_hat = net(X)<br>            l = loss(y_hat, y)<br>            l.backward()<br>            optimizer.step()<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                metric.add(l * X.shape[<span class="hljs-number">0</span>], d2l.accuracy(y_hat, y), X.shape[<span class="hljs-number">0</span>])<br>            timer.stop()<br>            train_l = metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]<br>            train_acc = metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]<br>            <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % (num_batches // <span class="hljs-number">5</span>) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> i == num_batches - <span class="hljs-number">1</span>:<br>                animator.add(epoch + (i + <span class="hljs-number">1</span>) / num_batches,<br>                             (train_l, train_acc, <span class="hljs-literal">None</span>))<br>        test_acc = evaluate_accuracy_gpu(net, test_iter)<br>        animator.add(epoch + <span class="hljs-number">1</span>, (<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, test_acc))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;loss <span class="hljs-subst">&#123;train_l:<span class="hljs-number">.3</span>f&#125;</span>, train acc <span class="hljs-subst">&#123;train_acc:<span class="hljs-number">.3</span>f&#125;</span>, &#x27;</span><br>          <span class="hljs-string">f&#x27;test acc <span class="hljs-subst">&#123;test_acc:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;metric[<span class="hljs-number">2</span>] * num_epochs / timer.<span class="hljs-built_in">sum</span>():<span class="hljs-number">.1</span>f&#125;</span> examples/sec &#x27;</span><br>          <span class="hljs-string">f&#x27;on <span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(device)&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">lr, num_epochs = <span class="hljs-number">0.9</span>, <span class="hljs-number">20</span><br>train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">loss <span class="hljs-number">0.356</span>, train acc <span class="hljs-number">0.868</span>, test acc <span class="hljs-number">0.849</span><br><span class="hljs-number">56757.7</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure><img src="/typora-user-images/image-20230214101934210.png"alt="result" /><figcaption aria-hidden="true">result</figcaption></figure><h2 id="alexnet">AlexNet</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>net = nn.Sequential(<br>    <span class="hljs-comment"># 这里使用一个11*11的更大窗口来捕捉对象。</span><br>    <span class="hljs-comment"># 同时，步幅为4，以减少输出的高度和宽度。</span><br>    <span class="hljs-comment"># 另外，输出通道的数目远大于LeNet</span><br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, kernel_size=<span class="hljs-number">11</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    <span class="hljs-comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span><br>    nn.Conv2d(<span class="hljs-number">96</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>), nn.ReLU(),<br>    nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    <span class="hljs-comment"># 使用三个连续的卷积层和较小的卷积窗口。</span><br>    <span class="hljs-comment"># 除了最后的卷积层，输出通道的数量进一步增加。</span><br>    <span class="hljs-comment"># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span><br>    nn.Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">384</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">384</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Flatten(),<br>    <span class="hljs-comment"># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span><br>    nn.Linear(<span class="hljs-number">6400</span>, <span class="hljs-number">4096</span>), nn.ReLU(),<br>    nn.Dropout(p=<span class="hljs-number">0.5</span>),<br>    nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>), nn.ReLU(),<br>    nn.Dropout(p=<span class="hljs-number">0.5</span>),<br>    <span class="hljs-comment"># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span><br>    nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X=layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape:\t&#x27;</span>,X.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Conv2d output shape:     torch.Size([1, 96, 54, 54])ReLU output shape:   torch.Size([1, 96, 54, 54])MaxPool2d output shape:  torch.Size([1, 96, 26, 26])Conv2d output shape:     torch.Size([1, 256, 26, 26])ReLU output shape:   torch.Size([1, 256, 26, 26])MaxPool2d output shape:  torch.Size([1, 256, 12, 12])Conv2d output shape:     torch.Size([1, 384, 12, 12])ReLU output shape:   torch.Size([1, 384, 12, 12])Conv2d output shape:     torch.Size([1, 384, 12, 12])ReLU output shape:   torch.Size([1, 384, 12, 12])Conv2d output shape:     torch.Size([1, 256, 12, 12])ReLU output shape:   torch.Size([1, 256, 12, 12])MaxPool2d output shape:  torch.Size([1, 256, 5, 5])Flatten output shape:    torch.Size([1, 6400])Linear output shape:     torch.Size([1, 4096])ReLU output shape:   torch.Size([1, 4096])Dropout output shape:    torch.Size([1, 4096])Linear output shape:     torch.Size([1, 4096])ReLU output shape:   torch.Size([1, 4096])Dropout output shape:    torch.Size([1, 4096])Linear output shape:     torch.Size([1, 10])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">lr, num_epochs = <span class="hljs-number">0.01</span>, <span class="hljs-number">10</span><br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输出</span><br>loss <span class="hljs-number">0.331</span>, train acc <span class="hljs-number">0.878</span>, test acc <span class="hljs-number">0.882</span><br><span class="hljs-number">1635.7</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure><img src="/typora-user-images/image-20230214102245051.png"alt="result" /><figcaption aria-hidden="true">result</figcaption></figure><h2 id="vggnet">VGGNet</h2><p>使用块，更大更深的AlexNet</p><ul><li><p>带填充以保持分辨率的卷积层；</p></li><li><p>非线性激活函数，如ReLU；</p></li><li><p>汇聚层，如最大汇聚层。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">vgg_block</span>(<span class="hljs-params">num_convs, in_channels, out_channels</span>):<br>    layers = []<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_convs):<br>        layers.append(nn.Conv2d(in_channels, out_channels,<br>                                kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>))<br>        layers.append(nn.ReLU())<br>        in_channels = out_channels<br>    layers.append(nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">conv_arch = ((<span class="hljs-number">1</span>, <span class="hljs-number">64</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">256</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">512</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">512</span>))<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">vgg</span>(<span class="hljs-params">conv_arch</span>):<br>    conv_blks = []<br>    in_channels = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> (num_convs, out_channels) <span class="hljs-keyword">in</span> conv_arch:<br>        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))<br>        in_channels = out_channels<br>    <span class="hljs-keyword">return</span> nn.Sequential(<br>        *conv_blks, <br>        nn.Flatten(),<br>        nn.Linear(out_channels * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">4096</span>), nn.ReLU(),<br>        nn.Dropout(<span class="hljs-number">0.5</span>), nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>), nn.ReLU(),<br>        nn.Dropout(<span class="hljs-number">0.5</span>), nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>)<br>    )<br>net = vgg(conv_arch)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.randn(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br><span class="hljs-keyword">for</span> blk <span class="hljs-keyword">in</span> net:<br>    X = blk(X)<br>    <span class="hljs-built_in">print</span>(blk.__class__.__name__, <span class="hljs-string">&#x27;output shape:\t&#x27;</span>, X.shape)<br>    <br></code></pre></td></tr></table></figure><pre><code class="hljs">Sequential output shape:     torch.Size([1, 64, 112, 112])Sequential output shape:     torch.Size([1, 128, 56, 56])Sequential output shape:     torch.Size([1, 256, 28, 28])Sequential output shape:     torch.Size([1, 512, 14, 14])Sequential output shape:     torch.Size([1, 512, 7, 7])Flatten output shape:    torch.Size([1, 25088])Linear output shape:     torch.Size([1, 4096])ReLU output shape:   torch.Size([1, 4096])Dropout output shape:    torch.Size([1, 4096])Linear output shape:     torch.Size([1, 4096])ReLU output shape:   torch.Size([1, 4096])Dropout output shape:    torch.Size([1, 4096])Linear output shape:     torch.Size([1, 10])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">ratio = <span class="hljs-number">4</span><br>small_conv_arch = [(pair[<span class="hljs-number">0</span>], pair[<span class="hljs-number">1</span>] // ratio) <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> conv_arch]<br>net = vgg(small_conv_arch)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.randn(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br><span class="hljs-keyword">for</span> blk <span class="hljs-keyword">in</span> net:<br>    X = blk(X)<br>    <span class="hljs-built_in">print</span>(blk.__class__.__name__, <span class="hljs-string">&#x27;output shape:\t&#x27;</span>, X.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Sequential output shape:     torch.Size([1, 16, 112, 112])Sequential output shape:     torch.Size([1, 32, 56, 56])Sequential output shape:     torch.Size([1, 64, 28, 28])Sequential output shape:     torch.Size([1, 128, 14, 14])Sequential output shape:     torch.Size([1, 128, 7, 7])Flatten output shape:    torch.Size([1, 6272])Linear output shape:     torch.Size([1, 4096])ReLU output shape:   torch.Size([1, 4096])Dropout output shape:    torch.Size([1, 4096])Linear output shape:     torch.Size([1, 4096])ReLU output shape:   torch.Size([1, 4096])Dropout output shape:    torch.Size([1, 4096])Linear output shape:     torch.Size([1, 10])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">lr, num_epochs, batch_size = <span class="hljs-number">0.05</span>, <span class="hljs-number">10</span>, <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br></code></pre></td></tr></table></figure><pre><code class="hljs">loss 0.177, train acc 0.935, test acc 0.8941091.9 examples/sec on cuda:0</code></pre><figure><img src="/typora-user-images/image-20230214140415757.png"alt="result" /><figcaption aria-hidden="true">result</figcaption></figure><h2 id="googlenetinception-v3">GoogleNet/Inception V3</h2><p>Inception 块</p><p>输入被copy成四块</p><figure><img src="/typora-user-images/image-20230214141018466.png"alt="image-20230214141018466" /><figcaption aria-hidden="true">image-20230214141018466</figcaption></figure><figure><img src="/typora-user-images/image-20230214141928373.png"alt="image-20230214141928373" /><figcaption aria-hidden="true">image-20230214141928373</figcaption></figure><p>用了很多1x1卷积，降低通道数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Inception</span>(nn.Module):<br>    <span class="hljs-comment"># c1--c4是每条路径的输出通道数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(Inception, self).__init__(**kwargs)<br>        <span class="hljs-comment"># 线路1，单1x1卷积层</span><br>        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 线路2，1x1卷积层后接3x3卷积层</span><br>        self.p2_1 = nn.Conv2d(in_channels, c2[<span class="hljs-number">0</span>], kernel_size=<span class="hljs-number">1</span>)<br>        self.p2_2 = nn.Conv2d(c2[<span class="hljs-number">0</span>], c2[<span class="hljs-number">1</span>], kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 线路3，1x1卷积层后接5x5卷积层</span><br>        self.p3_1 = nn.Conv2d(in_channels, c3[<span class="hljs-number">0</span>], kernel_size=<span class="hljs-number">1</span>)<br>        self.p3_2 = nn.Conv2d(c3[<span class="hljs-number">0</span>], c3[<span class="hljs-number">1</span>], kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 线路4，3x3最大汇聚层后接1x1卷积层</span><br>        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        p1 = F.relu(self.p1_1(x))<br>        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))<br>        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))<br>        p4 = F.relu(self.p4_2(self.p4_1(x)))<br>        <span class="hljs-comment"># 在通道维度上连结输出</span><br>        <span class="hljs-keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">b1 = nn.Sequential(nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>),<br>                   nn.ReLU(),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">b2 = nn.Sequential(nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">1</span>),<br>                   nn.ReLU(),<br>                   nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>                   nn.ReLU(),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">b3 = nn.Sequential(Inception(<span class="hljs-number">192</span>, <span class="hljs-number">64</span>, (<span class="hljs-number">96</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">32</span>), <span class="hljs-number">32</span>),<br>                   Inception(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, (<span class="hljs-number">128</span>, <span class="hljs-number">192</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">96</span>), <span class="hljs-number">64</span>),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">b4 = nn.Sequential(Inception(<span class="hljs-number">480</span>, <span class="hljs-number">192</span>, (<span class="hljs-number">96</span>, <span class="hljs-number">208</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">48</span>), <span class="hljs-number">64</span>),<br>                   Inception(<span class="hljs-number">512</span>, <span class="hljs-number">160</span>, (<span class="hljs-number">112</span>, <span class="hljs-number">224</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>),<br>                   Inception(<span class="hljs-number">512</span>, <span class="hljs-number">128</span>, (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>),<br>                   Inception(<span class="hljs-number">512</span>, <span class="hljs-number">112</span>, (<span class="hljs-number">144</span>, <span class="hljs-number">288</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>),<br>                   Inception(<span class="hljs-number">528</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">160</span>, <span class="hljs-number">320</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">b5 = nn.Sequential(Inception(<span class="hljs-number">832</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">160</span>, <span class="hljs-number">320</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>),<br>                   Inception(<span class="hljs-number">832</span>, <span class="hljs-number">384</span>, (<span class="hljs-number">192</span>, <span class="hljs-number">384</span>), (<span class="hljs-number">48</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>),<br>                   nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)),<br>                   nn.Flatten())<br><br>net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">96</span>, <span class="hljs-number">96</span>))<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X = layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape:\t&#x27;</span>, X.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Sequential output shape:     torch.Size([1, 64, 24, 24])Sequential output shape:     torch.Size([1, 192, 12, 12])Sequential output shape:     torch.Size([1, 480, 6, 6])Sequential output shape:     torch.Size([1, 832, 3, 3])Sequential output shape:     torch.Size([1, 1024])Linear output shape:     torch.Size([1, 10])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">96</span>)<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br></code></pre></td></tr></table></figure><pre><code class="hljs">loss 0.246, train acc 0.907, test acc 0.8931690.6 examples/sec on cuda:0</code></pre><figure><img src="/typora-user-images/image-20230214200912069.png"alt="image-20230214200912069" /><figcaption aria-hidden="true">image-20230214200912069</figcaption></figure><h2 id="resnet">ResNet</h2><figure><img src="/typora-user-images/image-20230214201006292.png"alt="image-20230214201006292" /><figcaption aria-hidden="true">image-20230214201006292</figcaption></figure><figure><img src="/typora-user-images/image-20230214201016846.png"alt="image-20230214201016846" /><figcaption aria-hidden="true">image-20230214201016846</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Residual</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_channels, num_channels,</span><br><span class="hljs-params">                 use_1x1conv=<span class="hljs-literal">False</span>, strides=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(input_channels, num_channels,<br>                               kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, stride=strides)<br>        self.conv2 = nn.Conv2d(num_channels, num_channels,<br>                               kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> use_1x1conv:<br>            self.conv3 = nn.Conv2d(input_channels, num_channels,<br>                                   kernel_size=<span class="hljs-number">1</span>, stride=strides)<br>        <span class="hljs-keyword">else</span>:<br>            self.conv3 = <span class="hljs-literal">None</span><br>        self.bn1 = nn.BatchNorm2d(num_channels)<br>        self.bn2 = nn.BatchNorm2d(num_channels)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        Y = F.relu(self.bn1(self.conv1(X)))<br>        Y = self.bn2(self.conv2(Y))<br>        <span class="hljs-keyword">if</span> self.conv3:<br>            X = self.conv3(X)<br>        Y += X<br>        <span class="hljs-keyword">return</span> F.relu(Y)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">b1 = nn.Sequential(nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>),<br>                   nn.BatchNorm2d(<span class="hljs-number">64</span>), nn.ReLU(),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>                  )<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_block</span>(<span class="hljs-params">input_channels, num_channels, num_residuals,</span><br><span class="hljs-params">                 first_block=<span class="hljs-literal">False</span></span>):<br>    blk = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residuals):<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> first_block:<br>            blk.append(Residual(input_channels, num_channels,<br>                                use_1x1conv=<span class="hljs-literal">True</span>, strides=<span class="hljs-number">2</span>))<br>        <span class="hljs-keyword">else</span>:<br>            blk.append(Residual(num_channels, num_channels))<br>    <span class="hljs-keyword">return</span> blk<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">b2 = nn.Sequential(*resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">2</span>, first_block=<span class="hljs-literal">True</span>))<br>b3 = nn.Sequential(*resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">2</span>))<br>b4 = nn.Sequential(*resnet_block(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">2</span>))<br>b5 = nn.Sequential(*resnet_block(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">2</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">net = nn.Sequential(b1, b2, b3, b4, b5,<br>                    nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)),<br>                    nn.Flatten(), nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X = layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape:\t&#x27;</span>, X.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">Sequential output shape:     torch.Size([1, 64, 56, 56])Sequential output shape:     torch.Size([1, 64, 56, 56])Sequential output shape:     torch.Size([1, 128, 28, 28])Sequential output shape:     torch.Size([1, 256, 14, 14])Sequential output shape:     torch.Size([1, 512, 7, 7])AdaptiveAvgPool2d output shape:  torch.Size([1, 512, 1, 1])Flatten output shape:    torch.Size([1, 512])Linear output shape:     torch.Size([1, 10])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">lr, num_epochs, batch_size = <span class="hljs-number">0.05</span>, <span class="hljs-number">10</span>, <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">96</span>)<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br></code></pre></td></tr></table></figure><pre><code class="hljs">loss 0.015, train acc 0.996, test acc 0.8932613.9 examples/sec on cuda:0</code></pre><figure><img src="/typora-user-images/image-20230214201027140.png"alt="image-20230214201027140" /><figcaption aria-hidden="true">image-20230214201027140</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>notes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[cs231n] Summary</title>
    <link href="/2023/02/18/%5Bcs231n%5DSummary/"/>
    <url>/2023/02/18/%5Bcs231n%5DSummary/</url>
    
    <content type="html"><![CDATA[<h1 id="cs231n-summary">cs231n: Summary</h1><h2 id="neural-networks">Neural Networks</h2><h3id="image-classification-data-driven-approach-k-nearest-neighbor-trainvaltest-splits"><ahref="https://cs231n.github.io/classification/">Image Classification:Data-driven Approach, k-Nearest Neighbor, train/val/test splits</a></h3><h4 id="image-classification">Image Classification</h4><p>Using a set of labeled images to predict categories of a set of testimages. Then we can measure the accuracy of the predictions.</p><h4 id="nearest-neighbor-classifier">Nearest Neighbor classifier</h4><ul><li>Choose a distance(L1, L2, etc.)</li><li>Calculate the sum of the distance between each text data and all thetrain data. Get the closest one. The label of this data is what theclassifier predict.</li></ul><h4 id="knn-classifier">kNN classifier</h4><p>Find the top k closest images and then have them vote on the label ofthe test image.</p><h4 id="validation-set-cross-validation">Validation set,cross-validation</h4><p><img src="/typora-user-images/image-20230203181619887.png" alt="image-20230203181619887" style="zoom:80%;" /></p><p>In this picture, fold 5 is the validation set. For cross-validation,we let fold 1-5 be validation set separately to help us choose somehyperparameters.</p><h3 id="linear-classification-support-vector-machine-softmax"><ahref="https://cs231n.github.io/linear-classify/">Linear classification:Support Vector Machine, Softmax</a></h3><p>What we want: a map from images to label scores. <spanclass="math inline">\(\Rightarrow\)</span> Score function, Lossfunction</p><h4 id="score-function">Score function</h4><p><span class="math inline">\(x_i\)</span> is a picture and <spanclass="math inline">\(W\)</span> is a matrix named weights. And <spanclass="math inline">\(b\)</span> is bias.<br /><span class="math display">\[f(x_i,W,b)=Wx_i+b\]</span> Sometimes we can extend <spanclass="math inline">\(W\)</span>:</p><p><img src="/typora-user-images/image-20230203184649909.png" alt="image-20230203184649909" style="zoom: 67%;" /></p><h5 id="preprocessing-center-the-data">Preprocessing: center thedata</h5><p>For photos, pixel value: [0~255]</p><p>Now: [0…255] <span class="math inline">\(\Rightarrow\)</span> [-127.. 127] <span class="math inline">\(\Rightarrow\)</span> [-1,1]</p><h4 id="loss-function">Loss function</h4><h5 id="multiclass-support-vector-machine-loss">Multiclass SupportVector Machine loss</h5><p>For image <span class="math inline">\(x_i\)</span> with label <spanclass="math inline">\(y_i\)</span>. Score function is <spanclass="math inline">\(f(x_i,W)\)</span>. Let <spanclass="math inline">\(s_j = f(x_i,W)_j\)</span>. Multiclass SVM loss:<span class="math display">\[L_i = \sum_{j\neq y_i}max(0,s_j-s_{y_i}+\Delta)\]</span></p><h6 id="regularization">Regularization</h6><p><span class="math display">\[R(W) = \sum_k\sum_l W_{k,l}^2\\L=\frac{1}{N}\sum_i L_i + \lambda R(W)\]</span></p><p>Or <span class="math display">\[L=\frac{1}{N}\sum_i\sum_{j\neqy_i}[max(0,f(x_i,W))_j-f(x_i,W)_{y_i}+\Delta]+\lambda\sum_k\sum_lW_{k,l}^2\]</span></p><h4 id="softmax-classifier">Softmax classifier</h4><p>With <span class="math inline">\(f(x_i,W)=Wx_i\)</span> unchanged,but for the loss: <span class="math display">\[L_i=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})\;or\;L_i=-f_{y_i}+log\sum_je^{f_j}\]</span></p><h3 id="optimization-stochastic-gradient-descent"><ahref="https://cs231n.github.io/optimization-1/">Optimization: StochasticGradient Descent</a></h3><h4 id="visualizing-the-loss-function">Visualizing the lossfunction</h4><p><img src="/typora-user-images/image-20230203191407300.png" alt="image-20230203191407300" style="zoom:80%;" /></p><figure><img src="/typora-user-images/image-20230203191516168.png"alt="image-20230203191516168" /><figcaption aria-hidden="true">image-20230203191516168</figcaption></figure><h4 id="optimization">Optimization</h4><ul><li><p>Random search</p></li><li><p>Random local search</p></li><li><p>Following the gradient</p></li></ul><p><span class="math display">\[\frac{df(x)}{dx}=\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}\]</span></p><p>Use this definition to calculate grad of all dims</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">eval_numerical_gradient</span>(<span class="hljs-params">f, x</span>):<br>  <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">  a naive implementation of numerical gradient of f at x</span><br><span class="hljs-string">  - f should be a function that takes a single argument</span><br><span class="hljs-string">  - x is the point (numpy array) to evaluate the gradient at</span><br><span class="hljs-string">  &quot;&quot;&quot;</span><br><br>  fx = f(x) <span class="hljs-comment"># evaluate function value at original point</span><br>  grad = np.zeros(x.shape)<br>  h = <span class="hljs-number">0.00001</span><br><br>  <span class="hljs-comment"># iterate over all indexes in x</span><br>  it = np.nditer(x, flags=[<span class="hljs-string">&#x27;multi_index&#x27;</span>], op_flags=[<span class="hljs-string">&#x27;readwrite&#x27;</span>])<br>  <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> it.finished:<br><br>    <span class="hljs-comment"># evaluate function at x+h</span><br>    ix = it.multi_index<br>    old_value = x[ix]<br>    x[ix] = old_value + h <span class="hljs-comment"># increment by h</span><br>    fxh = f(x) <span class="hljs-comment"># evalute f(x + h)</span><br>    x[ix] = old_value <span class="hljs-comment"># restore to previous value (very important!)</span><br><br>    <span class="hljs-comment"># compute the partial derivative</span><br>    grad[ix] = (fxh - fx) / h <span class="hljs-comment"># the slope</span><br>    it.iternext() <span class="hljs-comment"># step to next dimension</span><br><br>  <span class="hljs-keyword">return</span> grad<br></code></pre></td></tr></table></figure><p>In fact, we usually use <span class="math display">\[\frac{f(x+h)-f(x-h)}{2h}\]</span> But this method of calculation is expensive and not soaccurate. So maybe we can do it in a more “math” way.</p><p>Take loss function of SVM as an example: <spanclass="math display">\[L_i = \sum_{j\neq y_i}[max(0,w_j^Tx_i-w_{y_i}^Tx_i+\Delta)]\]</span> We can differentiate the function: <spanclass="math display">\[\Delta_{w_{y_i}}L_i = -(\sum_{j\neqy_i}1_{\{w_j^Tx_i-w_{y_i}^Tx_i+\Delta &gt;0\}}) \\\Delta_{w_{j}}L_i = 1_{\{w_j^Tx_i-w_{y_i}^Tx_i+\Delta &gt;0\}}x_i\]</span> With grad, we can do <strong>Gradient Descent</strong> bychoosing a suitable <strong>step size</strong>(or <strong>learningrate</strong>),</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>  weights_grad = evaluate_gradient(loss_fun, data, weights)<br>  weights += - step_size * weights_grad <span class="hljs-comment"># perform parameter update</span><br></code></pre></td></tr></table></figure><p>However, if the dataset is very big, this can be extremely expensive.So we introduce <strong>Mini-batch gradient descent</strong>. That meanswe can only evaluate on a small subset to get a gradient.</p><p>The extreme case of this method is the subset has only one image.This process is called <strong>Stochastic GradientDescent(SGD)</strong></p><h3 id="backpropagation-intuitions"><ahref="https://cs231n.github.io/optimization-2/">Backpropagation,Intuitions</a></h3><p>Make good use of chain rule</p><p><strong>Ex</strong></p><figure><img src="/typora-user-images/image-20230203202320171.png"alt="image-20230203202320171" /><figcaption aria-hidden="true">image-20230203202320171</figcaption></figure><ul><li>Add gate</li><li>Max gate</li><li>Multiply gate</li></ul><h3 id="neural-networks-part-1-setting-up-the-architecture"><ahref="https://cs231n.github.io/neural-networks-1/">Neural Networks Part1: Setting up the Architecture</a></h3><figure><img src="/typora-user-images/image-20230207121144890.png"alt="image-20230207121144890" /><figcaption aria-hidden="true">image-20230207121144890</figcaption></figure><p>input<span class="math inline">\(\rightarrow\)</span>input<spanclass="math inline">\(\cdot\)</span>weight<spanclass="math inline">\(\rightarrow\)</span>input<spanclass="math inline">\(\cdot\)</span>weight+bias<spanclass="math inline">\(\rightarrow\)</span>activate-f(input<spanclass="math inline">\(\cdot\)</span>weight+bias)</p><p><strong>Ex</strong> <span class="math display">\[s=W_2max(0,W_1x)\\s=W_3max(0,W_2max(0,W_1x))\]</span></p><h4 id="single-neuron-as-a-linear-classifier">Single neuron as a linearclassifier</h4><ul><li>Binary Softmax classifier</li><li>Binary SVM classifier</li><li>Regularization interpretation</li></ul><h4 id="commonly-used-activation-functions">Commonly used activationfunctions</h4><ul><li><strong>Sigmoid</strong></li></ul><p><span class="math display">\[\sigma(x)=\frac{1}{1+e^{-x}}\]</span></p><p>​ Shortcomings:</p><p>​ 1. kill gradients</p><p>​ 2. not zero-centered</p><p><img src="/typora-user-images/image-20230207123419875.png" alt="image-20230207123419875" style="zoom:50%;" /></p><ul><li><strong>Tanh</strong></li></ul><p><span class="math display">\[tanh(x)=2\sigma(2x)-1\]</span></p><p><img src="/typora-user-images/image-20230207123435272.png" alt="image-20230207123435272" style="zoom:50%;" /></p><p>​ Solve the problem of not zero-centered</p><ul><li><strong>ReLU</strong></li></ul><p><span class="math display">\[f(x)=max(0,x)\]</span></p><p>​ Advantages: greatly accelerate the convergence of stochasticdescent; not so expensive as tanh/sigmoid</p><p>​ Shortcoming: may die when a large gradient flow through a ReLUneuron. May solved by setting a proper learning rate</p><ul><li><strong>Leaky ReLU</strong></li></ul><p><span class="math display">\[f(x)=1_{(x&lt;0)}(\alpha x)+1_{(x&gt;=0)}(x)\]</span></p><p>​ in which <span class="math inline">\(\alpha\)</span> is very smalllike 0.01</p><ul><li><strong>Maxout</strong></li></ul><p><span class="math display">\[max(w_1^Tx+b_1,w_2^Tx+b_2)\]</span></p><blockquote><p><strong>Naming conventions</strong> When we talk about N-layer neuralnetwork, the input layer is not included in “N”.</p><p><strong>Output Layer</strong> Unlike other layers, the output layerneurons most commonly do not have an activation function. (while theoutput layer is used to present scores of every class, it’s easy tounderstand)</p><p><strong>Sizing neural networks</strong> Measure the size of neural:number of neurons/number of parameters</p></blockquote><h4 id="representational-power">Representational power</h4><p>Surveys has proven that given any continuous function f(x)and someϵ&gt;0, there exists a Neural Network g(x) with one hidden layer (with areasonable choice of non-linearity, e.g. sigmoid) such that∀x,∣f(x)−g(x)∣&lt;ϵ. In other words, the neural network can approximateany continuous function.</p><p>Practically, deeper networks can work better than asingle-hidden-layer network</p><p>For <strong>neural network</strong>, usually 3-layer networks will bebetter than 2-layer nets. But more deeper(4,5,6-layer) network rarelyhelps much more. But for <strong>convolutional network </strong>, it isdifferent. Depth is a very important factor.</p><p>Regularization is very important, which can elite overfitting.</p><h3 id="neural-networks-part-2-setting-up-the-data-and-the-loss"><ahref="https://cs231n.github.io/neural-networks-2/">Neural Networks Part2: Setting up the Data and the Loss</a></h3><h4 id="data-preprocessing">Data Preprocessing</h4><h5 id="mean-subtraction">Mean subtraction</h5><p>code: <code>X-=np.mean(X, axis = 0)</code></p><h5 id="normalization">Normalization</h5><p>code: <code>X/=np.std(X, axis = 0)</code></p><h5 id="pca-and-whitening">PCA and Whitening</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Assume input data matrix X of size [N x D]</span><br>X -= np.mean(X, axis = <span class="hljs-number">0</span>) <span class="hljs-comment"># zero-center the data (important)</span><br>cov = np.dot(X.T, X) / X.shape[<span class="hljs-number">0</span>] <span class="hljs-comment"># get the data covariance matrix</span><br></code></pre></td></tr></table></figure><p>compute the SVD factorization of the data covariance matrix:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">U,S,V = np.linalg.svd(cov)<br></code></pre></td></tr></table></figure><p>where the columns of<code class="language-plaintext highlighter-rouge">U</code> are theeigenvectors and<code class="language-plaintext highlighter-rouge">S</code> is a 1-Darray of the singular values. To decorrelate the data, we project theoriginal (but zero-centered) data into the eigenbasis:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Xrot = np.dot(X, U)<br></code></pre></td></tr></table></figure><p>dimensionality reduction:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Xrot_reduced = np.dot(X, U[:,:<span class="hljs-number">100</span>]) <span class="hljs-comment"># Xrot_reduced becomes [N x 100]</span><br></code></pre></td></tr></table></figure><p>For <strong>whitening</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># whiten the data:</span><br><span class="hljs-comment"># divide by the eigenvalues (which are square roots of the singular values)</span><br>Xwhite = Xrot / np.sqrt(S + <span class="hljs-number">1e-5</span>)<br></code></pre></td></tr></table></figure><figure><img src="/typora-user-images/image-20230207144339020.png"alt="image-20230207144339020" /><figcaption aria-hidden="true">image-20230207144339020</figcaption></figure><p><strong>Common pitfall</strong> The mean must be computed only overthe training data and then subtracted equally from all splits(train/val/test).</p><h4 id="weight-initialization">Weight Initialization</h4><p><strong>Pitfall: all zero initialization</strong> That will makeevery neuron do same thing.</p><p><strong>Small random numbers</strong> aim: <em>symmetrybreaking</em>. <code>W=0.01*np.random.randn(D, H)</code></p><p><strong>Calibrating the variances with 1/sqrt(n)</strong><code>W=np.random.randn(n) / sqrt(n)</code> where n is the number of itsinputs</p><p>Other: <strong>Sparse initialization</strong>, <strong>Initializingthe biases(0)</strong>, <strong>Batch Normalization</strong></p><h4 id="regularization-1">Regularization</h4><p><strong>L2 regularization</strong> May the most common. for all <spanclass="math inline">\(w\)</span>, add <spanclass="math inline">\(\frac{1}{2}\lambda w^2\)</span> to theobjective.</p><p><strong>L1 regularization</strong> for each weight <spanclass="math inline">\(w\)</span>, we add the term <spanclass="math inline">\(\lambda |w|\)</span> to the objective.</p><p>We can also combine the L1 regularization with the L2 regularization:<span class="math inline">\(\lambda _1|w|+\lambda_2w^2\)</span>, whichis called Elastic net regularization.</p><p><strong>Max norm constraints</strong> Enforce an absolute upper boundon the magnitude of the weight vector.</p><p><strong>Dropout</strong> keep a neuron active with some probability<span class="math inline">\(p\)</span> or setting it to zerootherwise</p><p>And there are many other methods about regularization. <strong>Biasregularization, per-layer regularization</strong>…</p><h4 id="loss-functions">Loss functions</h4><p>Let <span class="math inline">\(f=f(x_i;W)\)</span> to be theactivations of the output layer in a Neural Network.</p><p><strong>Classification</strong></p><p>SVM: <span class="math display">\[L_i=\sum_{j\neq y_i}max(0,f_j-f_{y_i}+1)\]</span></p><blockquote><p>sometimes use <spanclass="math inline">\(max(0,(f_j-f_{y_i}+1)^2)\)</span></p></blockquote><p>Softmax: <span class="math display">\[L_i=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})\]</span> <strong>Problem: Large number of classes</strong> When the setof labels is very large, Softmax becomes very expensive. It may behelpful to use <em>Hierarchical Softmax</em>.</p><p><strong>Attribute classification</strong></p><p>Both losses above assume that there is a single correct answer <spanclass="math inline">\(y_i\)</span>. But what if <spanclass="math inline">\(y_i\)</span> is a binary vector where everyexample may or may not have a certain attribute <spanclass="math display">\[L_i=\sum_jmax(0,1-y_{ij}f_j)\]</span> where <span class="math inline">\(y_{ij}\)</span> is either +1or -1</p><h3 id="neural-networks-part-3-learning-and-evaluation"><ahref="https://cs231n.github.io/neural-networks-3/">Neural Networks Part3: Learning and Evaluation</a></h3><p>Talking about learning process.</p><h4 id="gradient-checks">Gradient Checks</h4><p><span class="math display">\[\frac{df(x)}{dx}=\frac{f(x+h)-f(x-h)}{2h}\]</span></p><p>In order to compare the numerical gradient <spanclass="math inline">\(f_n&#39;\)</span> and analytic gradient <spanclass="math inline">\(f_a&#39;\)</span>, we can use relative error:<span class="math display">\[\frac{|f_a&#39;-f_b&#39;|}{max(|f_a&#39;|,|f_n&#39;|)}\]</span> ​ In practive:</p><ul><li>relative error &gt;<span class="math inline">\(1e-2\)</span>:probably wrong</li><li>1e-2&gt;relative error&gt;1e-4: uncomfortable…</li><li>1e-4&gt;relative error: OK…but without kinks(e.g. tanh and softmax),to high.</li><li>1e-7&gt;relative error: happy</li></ul><blockquote><p>should use double precision</p></blockquote><blockquote><p>if jump kinks, may not be exact</p></blockquote><p>In order to avoid above problems:</p><ul><li>Use only few datapoints</li><li>be careful with h</li></ul><figure><img src="/typora-user-images/image-20230207205258779.png"alt="image-20230207205258779" /><figcaption aria-hidden="true">image-20230207205258779</figcaption></figure><ul><li><p>Don’t let the regularization overwhelm the data</p></li><li><p>Remember to turn off dropout/augmentations</p></li></ul><h4 id="before-learning-sanity-checks-tipstricks">Before learning:sanity checks Tips/Tricks</h4><ul><li>Trace loss function</li></ul><p><img src="/typora-user-images/image-20230207210235489.png" alt="image-20230207210235489" style="zoom:80%;" /></p><p>​ The right picture may mean the data is so small</p><ul><li>Trace train/val accuracy</li></ul><p>​<img src="/typora-user-images/image-20230207210422908.png" alt="image-20230207210422908" style="zoom:80%;" /></p><ul><li>Ratio of weights: updates</li></ul><p>​ <strong>Ex</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># assume parameter vector W and its gradient vector dW</span><br>param_scale = np.linalg.norm(W.ravel())<br>update = -learning_rate*dW <span class="hljs-comment"># simple SGD update</span><br>update_scale = np.linalg.norm(update.ravel())<br>W += update <span class="hljs-comment"># the actual update</span><br><span class="hljs-built_in">print</span> update_scale / param_scale <span class="hljs-comment"># want ~1e-3</span><br></code></pre></td></tr></table></figure><ul><li><p>Activation / Gradient distributions per layer</p></li><li><p>First-layer Visualizations</p></li></ul><p>​ <strong>Ex</strong></p><p><img src="/typora-user-images/image-20230207211414465.png" alt="image-20230207211414465" style="zoom:80%;" /></p><p>​ Left: many noise. may in trouble. Right: Nice, smooth</p><h4 id="parameter-updates">Parameter updates</h4><h5 id="first-ordersgd-momentum-nesterov-momentum">First-order(SGD),momentum, Nesterov momentum</h5><ul><li><strong>Vanilla</strong> update</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x += - learning_rate * dx<br></code></pre></td></tr></table></figure><ul><li><strong>Momentum</strong> update</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Momentum update</span><br>v = mu * v - learning_rate * dx <span class="hljs-comment"># integrate velocity</span><br>x += v <span class="hljs-comment"># integrate position</span><br></code></pre></td></tr></table></figure><p>​ mu can be seen as the coefficient of friction in physics. (typical0.9)</p><ul><li><strong>Nesterov</strong> Momentum</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x_ahead = x + mu * v<br><span class="hljs-comment"># evaluate dx_ahead (the gradient at x_ahead instead of at x)</span><br>v = mu * v - learning_rate * dx_ahead<br>x += v<br></code></pre></td></tr></table></figure><figure><img src="/typora-user-images/image-20230207213105160.png"alt="image-20230207213105160" /><figcaption aria-hidden="true">image-20230207213105160</figcaption></figure><p>​ In practice, people like to rename <spanclass="math inline">\(x\_head\)</span> as <spanclass="math inline">\(x\)</span> :</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">v_prev = v <span class="hljs-comment"># back this up</span><br>v = mu * v - learning_rate * dx <span class="hljs-comment"># velocity update stays the same</span><br>x += -mu * v_prev + (<span class="hljs-number">1</span> + mu) * v <span class="hljs-comment"># position update changes form</span><br></code></pre></td></tr></table></figure><h5 id="annealing-the-learning-rate">Annealing the learning rate</h5><p>If the learning rate is too high, the system contains too muchkinetic energy, unable to settle down into deeper, but narrower parts ofthe loss function.</p><p>Normally, there are three methods to decay the learning rate:</p><ul><li><strong>Step decay</strong> Reduce the learning rate every fewepochs.</li><li><strong>Exponential decay</strong> In math: <spanclass="math inline">\(\alpha = \alpha_0e^{-kt}\)</span> in which <spanclass="math inline">\(\alpha_0,k\)</span> are hyperparameters and <spanclass="math inline">\(t\)</span> is the iteration number.</li><li><strong>1/t decay</strong> In math: <spanclass="math inline">\(\alpha = \alpha _0/(1+kt)\)</span> in which <spanclass="math inline">\(\alpha_0,k\)</span> are hyperparameters and <spanclass="math inline">\(t\)</span> is the iteration number</li></ul><p>​ In practice, we find that the step decay is slightly preferablebecause the hyperparameters it involves</p><h5 id="second-order-methods">Second order methods</h5><p>Basing on Newton’s method: <span class="math display">\[x\leftarrow x-[Hf(x)]^{-1}\nabla f(x)\]</span> Multiplying by the inverse Hessian leads the optimization totake more aggressive steps in directions of shallow curvature andshorter steps in directions of steep curvature</p><p>However, because of the expensive cost of calculating the Hessianmatrix, this method is impractical.</p><h5 id="per-parameter-adaptive-learning-rate-methods">Per-parameteradaptive learning rate methods</h5><p><strong>Adagrad</strong> is an adaptive learning rate methodoriginally proposed by <ahref="http://jmlr.org/papers/v12/duchi11a.html">Duchi et al.</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Assume the gradient dx and parameter vector x</span><br>cache += dx**<span class="hljs-number">2</span><br>x += - learning_rate * dx / (np.sqrt(cache) + eps)<br></code></pre></td></tr></table></figure><p><code>eps</code>: 1e-4~1e-8</p><p>shortcoming: the monotonic learning rate usually proves tooaggressive and stops learning too early</p><p><strong>RMSprop</strong> <ahref="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">slide29 of Lecture 6</a> of Geoff Hinton’s Coursera class: reduce Adagrad’saggressive</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">cache = decay_rate * cache + (<span class="hljs-number">1</span> - decay_rate) * dx**<span class="hljs-number">2</span><br>x += - learning_rate * dx / (np.sqrt(cache) + eps)<br></code></pre></td></tr></table></figure><p>in which <code>decay_rate</code> is a hyperparameter: 0.9, 0.99,0.999</p><p><strong>Adam</strong> a recently proposed update looks a bit likeRMSprop with momentum</p><p>simplified:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">m = beta1*m + (<span class="hljs-number">1</span>-beta1)*dx<br>v = beta2*v + (<span class="hljs-number">1</span>-beta2)*(dx**<span class="hljs-number">2</span>)<br>x += - learning_rate * m / (np.sqrt(v) + eps)<br></code></pre></td></tr></table></figure><p>recommend: <code>eps = 1e-8</code>, <code>beta1 = 0.9</code>,<code>beta2 = 0.999</code></p><p>With the <em>bias correction</em> mechanism, the update looks asfollows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># t is your iteration counter going from 1 to infinity</span><br>m = beta1*m + (<span class="hljs-number">1</span>-beta1)*dx<br>mt = m / (<span class="hljs-number">1</span>-beta1**t)<br>v = beta2*v + (<span class="hljs-number">1</span>-beta2)*(dx**<span class="hljs-number">2</span>)<br>vt = v / (<span class="hljs-number">1</span>-beta2**t)<br>x += - learning_rate * mt / (np.sqrt(vt) + eps)<br></code></pre></td></tr></table></figure><h4 id="hyperparameter-optimization">Hyperparameter optimization</h4><p>The most common hyperparameters in context of Neural Networksinclude:</p><ul><li>the initial learning rate</li><li>learning rate decay schedule(such as the decay constant)</li><li>regularization strength(L2 penalty, dropout strength)</li></ul><p><strong>Implementation</strong> make a worker and master</p><p><strong>Prefer one validation fold to cross-validation</strong> asingle validation set of respectable size substantially simplifies thecode base, without the need for cross-validation with multiple folds</p><p><strong>Hyperparameter ranges</strong><code>learning_rate = 10 ** uniform(-6, 1)</code></p><p><strong>Prefer random search to grid search</strong> can be easilyunderstand through following image:</p><figure><img src="/typora-user-images/image-20230208141840955.png"alt="image-20230208141840955" /><figcaption aria-hidden="true">image-20230208141840955</figcaption></figure><p><strong>Careful with best values on border</strong> if we find thatthe results is on the border, we may set a bad range and miss the truebest result.</p><p><strong>Stage your search from coarse to fine</strong></p><p><strong>Bayesian Hyperparameter Optimization</strong> <ahref="https://github.com/JasperSnoek/spearmint">Spearmint</a>, <ahref="http://www.cs.ubc.ca/labs/beta/Projects/SMAC/">SMAC</a>, and <ahref="http://jaberg.github.io/hyperopt/">Hyperopt</a>. However, inpractical settings with ConvNets it is still relatively difficult tobeat random search in a carefully-chosen intervals.</p><h4 id="evaluation">Evaluation</h4><h5 id="model-ensembles">Model Ensembles</h5><p>A reliable way to improve the performance of Neural Networks by a fewpercent: train multiple independent models, and at test time averagetheir predictions.</p><p>The number of models <span class="math inline">\(\uparrow\)</span>performance <span class="math inline">\(\uparrow\)</span> the variety ofmodels <span class="math inline">\(\uparrow\)</span> performance <spanclass="math inline">\(\uparrow\)</span></p><p>Some approaches to forming an ensemble</p><ul><li><strong>Same model, different initializations</strong></li></ul><p>​ Use cross-validation to determine the best hyperparameters, thentrain multiple models with the best set of hyperparameters but withdifferent random initialization.</p><p>​ shortcoming: variety is only due to iitialization</p><ul><li><p><strong>Top models discovered duringcross-validation</strong></p><p>Use cross-validation to determine the best hyperparameters, then pickthe top few (e.g. 10) models to form the ensemble.</p></li></ul><p>​ shortcoming: may include suboptimal models</p><ul><li><strong>Different checkpoints of a single model</strong></li></ul><p>​ Taking different checkpoints of a single network over time istraining is very expensive</p><p>​ shortcoming: lack of variety</p><p>​ advantage: very cheap</p><ul><li><strong>Running average of parameters during training</strong></li></ul><p>​</p><p>Shortcoming of model ensembles: take longer to evaluate on testexample.</p><p>A good idea: “distill” a good ensemble back to a single model byincorporating the ensemble log likelihoods into a modifiedobjective.</p><h2 id="convolutional-neural-networks">Convolutional NeuralNetworks</h2><h3id="convolutional-neural-networks-architectures-convolution-pooling-layers"><ahref="https://cs231n.github.io/convolutional-networks/">ConvolutionalNeural Networks: Architectures, Convolution / Pooling Layers</a></h3><p>CNN base on an assumption that the inputs are images.</p><h4 id="layers-used-to-build-convnets">Layers used to buildConvNets</h4><p><strong>Convolutional Layer, Pooling Layer, Fully-ConnectedLayer</strong></p><figure><img src="/typora-user-images/image-20230208144748173.png"alt="image-20230208144748173" /><figcaption aria-hidden="true">image-20230208144748173</figcaption></figure><h5 id="convolutional-layer">Convolutional Layer</h5><p><strong>filter</strong> with size like <spanclass="math inline">\(5\times 5\times 3\)</span></p><p>During the forward pass, we slide (more precisely, convolve) eachfilter across the width and height of the input volume and compute dotproducts between the entries of the filter and the input at anyposition</p><p><span class="math inline">\(\rightarrow\)</span> produce a separate2-dimensional activation map</p><p>The spatial extent of this connectivity: a hyperparameter called the<strong>receptive field</strong></p><p><strong>Depth, Stride, Zero-padding</strong></p><p><strong>Depth</strong>: depend on the number of filter. Called “deepcolumn” or “fiber”</p><p><strong>Stride</strong>: the number of pixel the filter will movewhen we slide it</p><p><strong>Zero-padding</strong>: pad the input volume with zeros aroundthe border</p><p>In math. the input volume size :<spanclass="math inline">\(W\)</span>, the receptive size of the Conv Layerneurons: <span class="math inline">\(F\)</span>, the stride with whichthey are applied: <span class="math inline">\(S\)</span>, the amount ofzero padding used: <span class="math inline">\(P\)</span></p><p>then the output: <spanclass="math inline">\((W-F+2P)/S+1\)</span></p><p><strong>Summary</strong></p><ul><li><p>Accept size: <span class="math inline">\(W_1\times H_1\timesD_1\)</span></p></li><li><p>Require:</p><ul><li>number of filters <span class="math inline">\(K\)</span></li><li>spatial extent <span class="math inline">\(F\)</span></li><li>stride <span class="math inline">\(S\)</span></li><li>the amount of zero padding <spanclass="math inline">\(P\)</span></li></ul></li><li><p>Produce size: <span class="math inline">\(W_2 \times H_2 \timesD_2\)</span></p><ul><li><span class="math inline">\(W_2=(W_1-F+2P)/S+1\)</span></li><li><span class="math inline">\(H_2=(H_1-F+2P)/S+1\)</span></li><li><span class="math inline">\(D_2=K\)</span></li></ul></li></ul><p>common set: <span class="math inline">\(F=3, S=1, P=1\)</span></p><p><strong>Backpropagation</strong> The backward pass for a convolutionoperation (for both the data and the weights) is also a convolution (butwith spatially-flipped filters).</p><p><strong><span class="math inline">\(1\times 1\)</span>convolution</strong> note that we have 3 channels. so it’s notmeaningless</p><p><strong>Dilated convolutions</strong> have filters that have spacesbetween each cell, called dilation.</p><p>##### Pooling layer</p><p>Common: Max</p><figure><img src="/typora-user-images/image-20230208152427080.png"alt="image-20230208152427080" /><figcaption aria-hidden="true">image-20230208152427080</figcaption></figure><ul><li><p>Accept size <span class="math inline">\(W_1\times H_1\timesD_1\)</span></p></li><li><p>Hyperparameters</p><ul><li>spatial extent <span class="math inline">\(F\)</span></li><li>stride <span class="math inline">\(S\)</span></li></ul></li><li><p>Produce size <span class="math inline">\(W_2\times H_2\timesD_2\)</span></p><ul><li><span class="math inline">\(W_2=(W_1-F)/S+1\)</span></li><li><span class="math inline">\(H_2=(H_1-F)/S+1\)</span></li><li><span class="math inline">\(D_2=D_1\)</span></li></ul></li></ul><p>Common: <span class="math inline">\(F=3, S=2\)</span> more commonly<span class="math inline">\(F=2, S=2\)</span></p><h5 id="normalization-layer">Normalization Layer</h5><p>These layers have since fallen out of favor because in practice theircontribution has been shown to be minimal, if any. For various types ofnormalizations, see the discussion in Alex Krizhevsky’s <ahref="http://code.google.com/p/cuda-convnet/wiki/LayerParams#Local_response_normalization_layer_(same_map)">cuda-convnetlibrary API</a>.</p><h5 id="fully-connected-layer">Fully-connected layer</h5><p>Just like Neural Network section</p><h5 id="converting-fully-connected-layers-to-conv-layers">ConvertingFully Connected layers to CONV layers</h5><p>Each of these conversions could in practice involve manipulating(e.g. reshaping) the weight matrix <spanclass="math inline">\(W\)</span> in each FC layer into CONV layerfilters. It turns out that this conversion allows us to “slide” theoriginal ConvNet very efficiently across many spatial positions in alarger image, in a single forward pass.</p><h4 id="convnet-architectures">ConvNet Architectures</h4><p>The most common pattern:</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]*M -&gt; [FC -&gt; RELU]*K -&gt; FC<br></code></pre></td></tr></table></figure><p><code>N &gt;= 0</code> (and usually <code>N &lt;= 3</code>),<code>M &gt;= 0</code>, <code>K &gt;= 0</code> (and usually<code>K &lt; 3</code>).</p><ul><li><p><code>INPUT -&gt; FC</code>, implements a linearclassifier.</p></li><li><p><code>INPUT -&gt; CONV -&gt; RELU -&gt; FC</code></p></li><li><p><code>INPUT -&gt; [CONV -&gt; RELU -&gt; POOL]*2 -&gt; FC -&gt; RELU -&gt; FC</code>.Here we see that there is a single CONV layer between every POOLlayer.</p></li><li><p><code>INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL]*3 -&gt; [FC -&gt; RELU]*2 -&gt; FC</code>Here we see two CONV layers stacked before every POOL layer.</p></li></ul><p><em>Prefer a stack of small filter CONV to one large receptive fieldCONV layer</em>.</p><h4 id="layer-sizing-patterns">Layer Sizing Patterns</h4><ul><li><strong>Input Layer</strong></li></ul><p>​ Should be divisible by 2 many times.</p><p>​ Ex. 32 (e.g. CIFAR-10), 64, 96 (e.g. STL-10), or 224 (e.g. commonImageNet ConvNets), 384, and 512.</p><ul><li><strong>Conv Layer</strong></li></ul><p>​ 3x3 or 5x5 Step <span class="math inline">\(S=1\)</span>, zero</p><ul><li><strong>Pool Layer</strong></li></ul><p>​ 2x2 , stride = 2(sometimes 3x3, stride = 2)</p><p><strong>Use stride of 1 in CONV</strong>:</p><ol type="1"><li>Smaller strides work better in practice.</li><li>Allows us to leave all spatial down-sampling to the POOL layers,with the CONV layers only transforming the input volume depth-wise.</li></ol><p><strong>Use padding</strong>:</p><p>If the CONV layers were to not zero-pad the inputs and only performvalid convolutions, then the size of the volumes would reduce by a smallamount after each CONV, and the <strong>information at theborders</strong> would be “washed away” too quickly.</p><p><strong>Compromising based on memory constrains</strong>:</p><p>people prefer to make the compromise at only the first CONV layer ofthe network. For example, one compromise might be to use a first CONVlayer with filter sizes of 7x7 and stride of 2 (as seen in a ZF net). Asanother example, an AlexNet uses filter sizes of 11x11 and stride of4.</p><h4 id="case-studies">Case Studies</h4><ul><li><strong>LeNet</strong></li><li><strong>AlexNet</strong></li><li><strong>ZF Net</strong></li><li><strong>GoogleNet</strong></li><li><strong>VGGNet</strong></li><li><strong>ResNet</strong></li></ul><p>VGG:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs routeros">INPUT: [224x224x3]        memory:  224<span class="hljs-number">*224</span><span class="hljs-number">*3</span>=150K   weights: 0<br>CONV3-64: [224x224x64]  memory:  224<span class="hljs-number">*224</span><span class="hljs-number">*64</span>=3.2M   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*3</span>)<span class="hljs-number">*64</span> = 1,728<br>CONV3-64: [224x224x64]  memory:  224<span class="hljs-number">*224</span><span class="hljs-number">*64</span>=3.2M   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*64</span>)<span class="hljs-number">*64</span> = 36,864<br>POOL2: [112x112x64]  memory:  112<span class="hljs-number">*112</span><span class="hljs-number">*64</span>=800K   weights: 0<br>CONV3-128: [112x112x128]  memory:  112<span class="hljs-number">*112</span><span class="hljs-number">*128</span>=1.6M   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*64</span>)<span class="hljs-number">*128</span> = 73,728<br>CONV3-128: [112x112x128]  memory:  112<span class="hljs-number">*112</span><span class="hljs-number">*128</span>=1.6M   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*128</span>)<span class="hljs-number">*128</span> = 147,456<br>POOL2: [56x56x128]  memory:  56<span class="hljs-number">*56</span><span class="hljs-number">*128</span>=400K   weights: 0<br>CONV3-256: [56x56x256]  memory:  56<span class="hljs-number">*56</span><span class="hljs-number">*256</span>=800K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*128</span>)<span class="hljs-number">*256</span> = 294,912<br>CONV3-256: [56x56x256]  memory:  56<span class="hljs-number">*56</span><span class="hljs-number">*256</span>=800K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*256</span>)<span class="hljs-number">*256</span> = 589,824<br>CONV3-256: [56x56x256]  memory:  56<span class="hljs-number">*56</span><span class="hljs-number">*256</span>=800K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*256</span>)<span class="hljs-number">*256</span> = 589,824<br>POOL2: [28x28x256]  memory:  28<span class="hljs-number">*28</span><span class="hljs-number">*256</span>=200K   weights: 0<br>CONV3-512: [28x28x512]  memory:  28<span class="hljs-number">*28</span><span class="hljs-number">*512</span>=400K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*256</span>)<span class="hljs-number">*512</span> = 1,179,648<br>CONV3-512: [28x28x512]  memory:  28<span class="hljs-number">*28</span><span class="hljs-number">*512</span>=400K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*512</span>)<span class="hljs-number">*512</span> = 2,359,296<br>CONV3-512: [28x28x512]  memory:  28<span class="hljs-number">*28</span><span class="hljs-number">*512</span>=400K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*512</span>)<span class="hljs-number">*512</span> = 2,359,296<br>POOL2: [14x14x512]  memory:  14<span class="hljs-number">*14</span><span class="hljs-number">*512</span>=100K   weights: 0<br>CONV3-512: [14x14x512]  memory:  14<span class="hljs-number">*14</span><span class="hljs-number">*512</span>=100K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*512</span>)<span class="hljs-number">*512</span> = 2,359,296<br>CONV3-512: [14x14x512]  memory:  14<span class="hljs-number">*14</span><span class="hljs-number">*512</span>=100K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*512</span>)<span class="hljs-number">*512</span> = 2,359,296<br>CONV3-512: [14x14x512]  memory:  14<span class="hljs-number">*14</span><span class="hljs-number">*512</span>=100K   weights: (3<span class="hljs-number">*3</span><span class="hljs-number">*512</span>)<span class="hljs-number">*512</span> = 2,359,296<br>POOL2: [7x7x512]  memory:  7<span class="hljs-number">*7</span><span class="hljs-number">*512</span>=25K  weights: 0<br>FC: [1x1x4096]  memory:  4096  weights: 7<span class="hljs-number">*7</span><span class="hljs-number">*512</span><span class="hljs-number">*4096</span> = 102,760,448<br>FC: [1x1x4096]  memory:  4096  weights: 4096<span class="hljs-number">*4096</span> = 16,777,216<br>FC: [1x1x1000]  memory:  1000 weights: 4096<span class="hljs-number">*1000</span> = 4,096,000<br><br>TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~<span class="hljs-number">*2</span> <span class="hljs-keyword">for</span> bwd)<br>TOTAL params: 138M parameters<br></code></pre></td></tr></table></figure><p><strong>Computational Considerations</strong></p><p>There are three major sources of memory to keep track of:</p><ul><li><p>From the intermediate volume sizes</p></li><li><p>From the parameter sizes</p></li><li><p>Every ConvNet implementation has to maintain<strong>miscellaneous</strong> memory, such as the image data batches,perhaps their augmented versions, etc.</p></li></ul><h3id="transfer-learning-and-fine-tuning-convolutional-neural-networks"><ahref="https://cs231n.github.io/transfer-learning/">Transfer Learning andFine-tuning Convolutional Neural Networks</a></h3><h4 id="transfer-learning">Transfer Learning</h4><figure><img src="/typora-user-images/image-20230210153134566.png"alt="image-20230210153134566" /><figcaption aria-hidden="true">image-20230210153134566</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>notes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[iGEM] Modelling Group: introduction about Markdown and LaTeX</title>
    <link href="/2023/01/25/Modelling-Group-introduction-about-Markdown-and-LaTeX/"/>
    <url>/2023/01/25/Modelling-Group-introduction-about-Markdown-and-LaTeX/</url>
    
    <content type="html"><![CDATA[<h1 id="markdown">Markdown</h1><p>What is markdown?</p><ul><li>language(light)</li><li>easy to control</li></ul><h2 id="titles">Titles</h2><h1 id="im-1">I'm 1</h1><h2 id="im-2">I'm 2</h2><h3 id="im-3">I'm 3</h3><h4 id="im-4">I'm 4</h4><h5 id="im-5">I'm 5</h5><h6 id="im-6">I'm 6</h6><p class="heading" id="im-7">I'm 7</p><p>for title: 1-6, no 7</p><h2 id="bold-italic-bolditalic">bold, italic, bold&amp;italic</h2><p>I am a <em>sentence</em>. I like eat <strong>beef</strong>.</p><p>I am a <strong><em>student</em></strong>.</p><h2 id="links-photos">links, photos</h2><p><a href="https://www.baidu.com">Baidu</a></p><figure><img src="/img/me.jpg" alt="me" /><figcaption aria-hidden="true">me</figcaption></figure><h2 id="quote">quote</h2><blockquote><p>Lu Xun: people should eat.</p></blockquote><h2 id="list-2-types">list: 2 types</h2><ul><li>one<ul><li>two</li></ul></li><li>three<ul><li>four<ul><li>five</li></ul></li></ul></li></ul><ol type="1"><li>1</li><li>3</li></ol><p>if no " ":</p><p>1.123</p><h2 id="code">code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">sum</span>=<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>  <span class="hljs-built_in">sum</span> += i<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span><br>&#123;<br>  balabala;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="table">table</h2><table><thead><tr class="header"><th style="text-align: left;">Header One</th><th style="text-align: left;">Header Two</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">Item One</td><td style="text-align: left;">Item Two</td></tr></tbody></table><h2 id="others">others</h2><p><del>I eat rubbish yesterday</del></p><p><u>this sentence is important</u></p><p>I must dosomething.<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="guess">[1]</span></a></sup></p><h2 id="math">math</h2><p>We all know that 2+3=5</p><p>we all know that <spanclass="math inline">\(1+\frac{1}{2}=\frac{3}{2}\)</span>。<spanclass="math inline">\(2^2=4\)</span>, <spanclass="math inline">\(CO_2\)</span>, <spanclass="math inline">\(x_{11}\)</span> <span class="math display">\[1+\frac{1}{2}\]</span></p><p><span class="math display">\[\begin{pmatrix}x_{11} &amp; x_{12} \\x_{21} &amp; x_{22}\end{pmatrix}\]</span></p><p><span class="math display">\[X=\sum^{n}_{i=1} \frac{\Pi_{j=1}^{m}x_{ij}}{\sigma_{i}k_i^2}\]</span></p><p><span class="math display">\[\begin{equation}x=\frac{\partial T}{\partial V}c_{Boltzman}\alpha_x\end{equation}\]</span></p><p><span class="math display">\[\begin{equation*}y=\frac{\partial T}{\partial M}c_{Boltzman}\alpha_y\end{equation*}\]</span></p><p><span class="math display">\[\begin{equation}z=\frac{\partial T}{\partial K}c_{Boltzman}\alpha_z\end{equation}\]</span></p><p><span class="math display">\[\begin{align}1&amp;=0+1\\2&amp;=1+1-0-1+1\\444&amp;=400+40+4\end{align}\]</span></p><p><span class="math display">\[\begin{align*}a+b+c&amp;=x\\x&amp;=a+b+c\end{align*}\]</span></p><p><span class="math display">\[A+B\rightarrow C\\\]</span> (of course not end…)</p><hr /><h1 id="latex">LaTex</h1><p><span class="math inline">\(\LaTeX\)</span></p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>guess<a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    
    <tags>
      
      <tag>teach</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello world</title>
    <link href="/2023/01/23/Hello-world/"/>
    <url>/2023/01/23/Hello-world/</url>
    
    <content type="html"><![CDATA[<h1 id="hello-world">HELLO WORLD</h1><h2 id="my-first-try-of-blog">My First Try of Blog</h2><p>Thanks to the help of Wang Zhili and Hu shukai, I managed to build myfirst blog today.</p><p>My blog will all in English, recording some courses notes and dailyfeelings.</p>]]></content>
    
    
    
    <tags>
      
      <tag>intro</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
